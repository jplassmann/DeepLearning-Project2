{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "from math import pi\n",
    "from Activation import ReLU, Tanh\n",
    "from Layer import Linear\n",
    "from Sequential import Sequential\n",
    "from Loss import LossMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(model, test_input, test_target):\n",
    "    \n",
    "    output = model.forward(test_input)\n",
    "    \n",
    "    output[output >= 0] = 1\n",
    "    output[output < 0] = -1\n",
    "    goodValue = torch.full((len(output), 1), 0, dtype=torch.float32)\n",
    "    goodValue[output == test_target] = 1\n",
    "    return goodValue.sum()/len(goodValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = LossMSE()\n",
    "model = Sequential(\n",
    "            Linear(2, 25),\n",
    "            ReLU(),\n",
    "            Linear(25, 50),\n",
    "            ReLU(),\n",
    "            Linear(50, 25),\n",
    "            ReLU(),\n",
    "            Linear(25, 1),\n",
    "            Tanh()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9477, 0.9929],\n",
      "        [0.0250, 0.3855],\n",
      "        [0.1595, 0.4901],\n",
      "        ...,\n",
      "        [0.3516, 0.8351],\n",
      "        [0.6575, 0.9193],\n",
      "        [0.4186, 0.4123]])\n",
      "tensor([0.4996, 0.4998]) tensor([0.2945, 0.2875])\n",
      "tensor([[ 1.5214,  1.7149],\n",
      "        [-1.6118, -0.3974],\n",
      "        [-1.1550, -0.0337],\n",
      "        ...,\n",
      "        [-0.5028,  1.1660],\n",
      "        [ 0.5360,  1.4589],\n",
      "        [-0.2751, -0.3045]])\n"
     ]
    }
   ],
   "source": [
    "train_input = torch.rand((1000,2))\n",
    "train_target = torch.rand((1000,1))\n",
    "train_target[((train_input-0.5)**2).sum(1) < 1/(2*pi)] = -1 \n",
    "train_target[((train_input-0.5)**2).sum(1) >= 1/(2*pi)] = 1\n",
    "\n",
    "test_input = torch.rand((1000,2))\n",
    "test_target = torch.rand((1000,1))\n",
    "test_target[((test_input-0.5)**2).sum(1) < 1/(2*pi)] = -1 \n",
    "test_target[((test_input-0.5)**2).sum(1) >= 1/(2*pi)] = 1\n",
    "\n",
    "#Normalization\n",
    "mu, std = train_input.mean(0), train_input.std(0)\n",
    "train_input.sub_(mu).div_(std)\n",
    "print(test_input)\n",
    "print(mu,std)\n",
    "test_input.sub_(mu).div_(std)\n",
    "print(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E 0 Loss : 1.80 / train accuracy: 0.57 / test accuracy: 0.58\n",
      "E 10 Loss : 1.55 / train accuracy: 0.61 / test accuracy: 0.59\n",
      "E 20 Loss : 1.53 / train accuracy: 0.61 / test accuracy: 0.60\n",
      "E 30 Loss : 1.53 / train accuracy: 0.61 / test accuracy: 0.60\n",
      "E 40 Loss : 1.50 / train accuracy: 0.62 / test accuracy: 0.61\n",
      "E 50 Loss : 1.52 / train accuracy: 0.62 / test accuracy: 0.61\n",
      "E 60 Loss : 1.51 / train accuracy: 0.63 / test accuracy: 0.62\n",
      "E 70 Loss : 1.49 / train accuracy: 0.63 / test accuracy: 0.62\n",
      "E 80 Loss : 1.47 / train accuracy: 0.63 / test accuracy: 0.62\n",
      "E 90 Loss : 1.47 / train accuracy: 0.63 / test accuracy: 0.62\n",
      "E 100 Loss : 1.46 / train accuracy: 0.63 / test accuracy: 0.62\n",
      "E 110 Loss : 1.45 / train accuracy: 0.64 / test accuracy: 0.63\n",
      "E 120 Loss : 1.44 / train accuracy: 0.63 / test accuracy: 0.63\n",
      "E 130 Loss : 1.44 / train accuracy: 0.64 / test accuracy: 0.63\n",
      "E 140 Loss : 1.41 / train accuracy: 0.65 / test accuracy: 0.64\n",
      "E 150 Loss : 1.34 / train accuracy: 0.66 / test accuracy: 0.64\n",
      "E 160 Loss : 1.29 / train accuracy: 0.67 / test accuracy: 0.66\n",
      "E 170 Loss : 1.28 / train accuracy: 0.68 / test accuracy: 0.66\n",
      "E 180 Loss : 1.28 / train accuracy: 0.68 / test accuracy: 0.67\n",
      "E 190 Loss : 1.27 / train accuracy: 0.68 / test accuracy: 0.67\n",
      "E 200 Loss : 1.26 / train accuracy: 0.68 / test accuracy: 0.67\n",
      "E 210 Loss : 1.24 / train accuracy: 0.69 / test accuracy: 0.67\n",
      "E 220 Loss : 1.22 / train accuracy: 0.69 / test accuracy: 0.68\n",
      "E 230 Loss : 1.19 / train accuracy: 0.70 / test accuracy: 0.69\n",
      "E 240 Loss : 1.17 / train accuracy: 0.70 / test accuracy: 0.70\n",
      "E 250 Loss : 1.16 / train accuracy: 0.70 / test accuracy: 0.70\n",
      "E 260 Loss : 1.15 / train accuracy: 0.71 / test accuracy: 0.70\n",
      "E 270 Loss : 1.15 / train accuracy: 0.71 / test accuracy: 0.70\n",
      "E 280 Loss : 1.15 / train accuracy: 0.71 / test accuracy: 0.70\n",
      "E 290 Loss : 1.15 / train accuracy: 0.70 / test accuracy: 0.69\n",
      "E 300 Loss : 1.14 / train accuracy: 0.71 / test accuracy: 0.69\n",
      "E 310 Loss : 0.99 / train accuracy: 0.75 / test accuracy: 0.75\n",
      "E 320 Loss : 0.92 / train accuracy: 0.76 / test accuracy: 0.77\n",
      "E 330 Loss : 0.91 / train accuracy: 0.77 / test accuracy: 0.77\n",
      "E 340 Loss : 0.91 / train accuracy: 0.77 / test accuracy: 0.77\n",
      "E 350 Loss : 0.89 / train accuracy: 0.77 / test accuracy: 0.77\n",
      "E 360 Loss : 0.90 / train accuracy: 0.75 / test accuracy: 0.76\n",
      "E 370 Loss : 0.89 / train accuracy: 0.78 / test accuracy: 0.77\n",
      "E 380 Loss : 0.88 / train accuracy: 0.76 / test accuracy: 0.76\n",
      "E 390 Loss : 0.90 / train accuracy: 0.75 / test accuracy: 0.74\n",
      "E 400 Loss : 0.87 / train accuracy: 0.78 / test accuracy: 0.77\n",
      "E 410 Loss : 0.86 / train accuracy: 0.77 / test accuracy: 0.76\n",
      "E 420 Loss : 0.87 / train accuracy: 0.78 / test accuracy: 0.76\n",
      "E 430 Loss : 0.90 / train accuracy: 0.77 / test accuracy: 0.75\n",
      "E 440 Loss : 0.86 / train accuracy: 0.78 / test accuracy: 0.77\n",
      "E 450 Loss : 0.86 / train accuracy: 0.78 / test accuracy: 0.77\n",
      "E 460 Loss : 0.87 / train accuracy: 0.78 / test accuracy: 0.76\n",
      "E 470 Loss : 0.85 / train accuracy: 0.78 / test accuracy: 0.77\n",
      "E 480 Loss : 0.87 / train accuracy: 0.77 / test accuracy: 0.75\n",
      "E 490 Loss : 0.85 / train accuracy: 0.78 / test accuracy: 0.77\n",
      "E 500 Loss : 0.84 / train accuracy: 0.79 / test accuracy: 0.77\n",
      "E 510 Loss : 0.84 / train accuracy: 0.79 / test accuracy: 0.78\n",
      "E 520 Loss : 0.84 / train accuracy: 0.79 / test accuracy: 0.78\n",
      "E 530 Loss : 0.88 / train accuracy: 0.77 / test accuracy: 0.75\n",
      "E 540 Loss : 0.90 / train accuracy: 0.76 / test accuracy: 0.74\n",
      "E 550 Loss : 0.83 / train accuracy: 0.79 / test accuracy: 0.78\n",
      "E 560 Loss : 0.82 / train accuracy: 0.79 / test accuracy: 0.78\n",
      "E 570 Loss : 0.83 / train accuracy: 0.77 / test accuracy: 0.77\n",
      "E 580 Loss : 0.82 / train accuracy: 0.79 / test accuracy: 0.78\n",
      "E 590 Loss : 0.82 / train accuracy: 0.79 / test accuracy: 0.78\n",
      "E 600 Loss : 0.82 / train accuracy: 0.79 / test accuracy: 0.78\n",
      "E 610 Loss : 0.83 / train accuracy: 0.79 / test accuracy: 0.78\n",
      "E 620 Loss : 0.86 / train accuracy: 0.77 / test accuracy: 0.75\n",
      "E 630 Loss : 0.82 / train accuracy: 0.79 / test accuracy: 0.77\n",
      "E 640 Loss : 0.83 / train accuracy: 0.79 / test accuracy: 0.78\n",
      "E 650 Loss : 0.82 / train accuracy: 0.78 / test accuracy: 0.77\n",
      "E 660 Loss : 0.83 / train accuracy: 0.79 / test accuracy: 0.78\n",
      "E 670 Loss : 0.82 / train accuracy: 0.80 / test accuracy: 0.79\n",
      "E 680 Loss : 0.79 / train accuracy: 0.79 / test accuracy: 0.78\n",
      "E 690 Loss : 0.80 / train accuracy: 0.79 / test accuracy: 0.78\n",
      "E 700 Loss : 0.82 / train accuracy: 0.78 / test accuracy: 0.78\n",
      "E 710 Loss : 0.81 / train accuracy: 0.79 / test accuracy: 0.78\n",
      "E 720 Loss : 0.80 / train accuracy: 0.80 / test accuracy: 0.79\n",
      "E 730 Loss : 0.79 / train accuracy: 0.80 / test accuracy: 0.79\n",
      "E 740 Loss : 0.78 / train accuracy: 0.80 / test accuracy: 0.79\n",
      "E 750 Loss : 0.78 / train accuracy: 0.80 / test accuracy: 0.79\n",
      "E 760 Loss : 0.81 / train accuracy: 0.78 / test accuracy: 0.77\n",
      "E 770 Loss : 0.78 / train accuracy: 0.79 / test accuracy: 0.78\n",
      "E 780 Loss : 0.78 / train accuracy: 0.80 / test accuracy: 0.79\n",
      "E 790 Loss : 0.77 / train accuracy: 0.80 / test accuracy: 0.80\n",
      "E 800 Loss : 0.78 / train accuracy: 0.80 / test accuracy: 0.79\n",
      "E 810 Loss : 0.80 / train accuracy: 0.80 / test accuracy: 0.80\n",
      "E 820 Loss : 0.83 / train accuracy: 0.77 / test accuracy: 0.76\n",
      "E 830 Loss : 0.76 / train accuracy: 0.81 / test accuracy: 0.80\n",
      "E 840 Loss : 0.68 / train accuracy: 0.83 / test accuracy: 0.83\n",
      "E 850 Loss : 0.59 / train accuracy: 0.88 / test accuracy: 0.87\n",
      "E 860 Loss : 0.50 / train accuracy: 0.86 / test accuracy: 0.85\n",
      "E 870 Loss : 0.38 / train accuracy: 0.89 / test accuracy: 0.90\n",
      "E 880 Loss : 0.42 / train accuracy: 0.77 / test accuracy: 0.75\n",
      "E 890 Loss : 0.44 / train accuracy: 0.86 / test accuracy: 0.85\n",
      "E 900 Loss : 0.56 / train accuracy: 0.94 / test accuracy: 0.93\n",
      "E 910 Loss : 0.61 / train accuracy: 0.93 / test accuracy: 0.94\n",
      "E 920 Loss : 0.28 / train accuracy: 0.81 / test accuracy: 0.81\n",
      "E 930 Loss : 0.52 / train accuracy: 0.91 / test accuracy: 0.91\n",
      "E 940 Loss : 0.40 / train accuracy: 0.92 / test accuracy: 0.91\n",
      "E 950 Loss : 0.33 / train accuracy: 0.80 / test accuracy: 0.78\n",
      "E 960 Loss : 0.40 / train accuracy: 0.94 / test accuracy: 0.92\n",
      "E 970 Loss : 0.29 / train accuracy: 0.86 / test accuracy: 0.85\n",
      "E 980 Loss : 0.31 / train accuracy: 0.88 / test accuracy: 0.87\n",
      "E 990 Loss : 0.24 / train accuracy: 0.87 / test accuracy: 0.86\n",
      "E 1000 Loss : 0.31 / train accuracy: 0.95 / test accuracy: 0.93\n",
      "E 1010 Loss : 0.28 / train accuracy: 0.84 / test accuracy: 0.82\n",
      "E 1020 Loss : 0.39 / train accuracy: 0.90 / test accuracy: 0.90\n",
      "E 1030 Loss : 0.33 / train accuracy: 0.87 / test accuracy: 0.86\n",
      "E 1040 Loss : 0.54 / train accuracy: 0.93 / test accuracy: 0.92\n",
      "E 1050 Loss : 0.28 / train accuracy: 0.95 / test accuracy: 0.94\n",
      "E 1060 Loss : 0.22 / train accuracy: 0.86 / test accuracy: 0.84\n",
      "E 1070 Loss : 0.23 / train accuracy: 0.86 / test accuracy: 0.84\n",
      "E 1080 Loss : 0.19 / train accuracy: 0.93 / test accuracy: 0.94\n",
      "E 1090 Loss : 0.54 / train accuracy: 0.92 / test accuracy: 0.92\n",
      "E 1100 Loss : 0.19 / train accuracy: 0.91 / test accuracy: 0.92\n",
      "E 1110 Loss : 0.58 / train accuracy: 0.91 / test accuracy: 0.91\n",
      "E 1120 Loss : 0.40 / train accuracy: 0.95 / test accuracy: 0.95\n",
      "E 1130 Loss : 0.54 / train accuracy: 0.92 / test accuracy: 0.92\n",
      "E 1140 Loss : 0.61 / train accuracy: 0.88 / test accuracy: 0.87\n",
      "E 1150 Loss : 0.47 / train accuracy: 0.92 / test accuracy: 0.91\n",
      "E 1160 Loss : 0.60 / train accuracy: 0.90 / test accuracy: 0.89\n",
      "E 1170 Loss : 0.53 / train accuracy: 0.94 / test accuracy: 0.93\n",
      "E 1180 Loss : 0.56 / train accuracy: 0.92 / test accuracy: 0.92\n",
      "E 1190 Loss : 0.45 / train accuracy: 0.94 / test accuracy: 0.94\n",
      "E 1200 Loss : 0.19 / train accuracy: 0.91 / test accuracy: 0.90\n",
      "E 1210 Loss : 0.23 / train accuracy: 0.94 / test accuracy: 0.93\n",
      "E 1220 Loss : 0.22 / train accuracy: 0.87 / test accuracy: 0.86\n",
      "E 1230 Loss : 0.32 / train accuracy: 0.95 / test accuracy: 0.94\n",
      "E 1240 Loss : 0.30 / train accuracy: 0.94 / test accuracy: 0.94\n",
      "E 1250 Loss : 0.49 / train accuracy: 0.93 / test accuracy: 0.94\n",
      "E 1260 Loss : 0.31 / train accuracy: 0.87 / test accuracy: 0.87\n",
      "E 1270 Loss : 0.39 / train accuracy: 0.93 / test accuracy: 0.92\n",
      "E 1280 Loss : 0.26 / train accuracy: 0.94 / test accuracy: 0.93\n",
      "E 1290 Loss : 0.51 / train accuracy: 0.94 / test accuracy: 0.94\n",
      "E 1300 Loss : 0.19 / train accuracy: 0.92 / test accuracy: 0.92\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E 1310 Loss : 0.42 / train accuracy: 0.93 / test accuracy: 0.93\n",
      "E 1320 Loss : 0.20 / train accuracy: 0.90 / test accuracy: 0.89\n",
      "E 1330 Loss : 0.26 / train accuracy: 0.88 / test accuracy: 0.88\n",
      "E 1340 Loss : 0.24 / train accuracy: 0.93 / test accuracy: 0.92\n",
      "E 1350 Loss : 0.19 / train accuracy: 0.93 / test accuracy: 0.92\n",
      "E 1360 Loss : 0.45 / train accuracy: 0.94 / test accuracy: 0.93\n",
      "E 1370 Loss : 0.20 / train accuracy: 0.91 / test accuracy: 0.90\n",
      "E 1380 Loss : 0.24 / train accuracy: 0.93 / test accuracy: 0.92\n",
      "E 1390 Loss : 0.26 / train accuracy: 0.92 / test accuracy: 0.91\n",
      "E 1400 Loss : 0.16 / train accuracy: 0.93 / test accuracy: 0.93\n",
      "E 1410 Loss : 0.22 / train accuracy: 0.93 / test accuracy: 0.92\n",
      "E 1420 Loss : 0.36 / train accuracy: 0.91 / test accuracy: 0.90\n",
      "E 1430 Loss : 0.27 / train accuracy: 0.93 / test accuracy: 0.92\n",
      "E 1440 Loss : 0.28 / train accuracy: 0.87 / test accuracy: 0.86\n",
      "E 1450 Loss : 0.15 / train accuracy: 0.95 / test accuracy: 0.95\n",
      "E 1460 Loss : 0.20 / train accuracy: 0.92 / test accuracy: 0.91\n",
      "E 1470 Loss : 0.30 / train accuracy: 0.96 / test accuracy: 0.94\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-eb03193d1b3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mgradwrrtxL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradwrrtxL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/EPFL/DeepLearning/DeepLearning-Project2/Sequential.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, *gradwrtoutput)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mgradwrtoutputTensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradwrtoutputTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mself\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/EPFL/DeepLearning/DeepLearning-Project2/Activation.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradwrtoutput)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradwrtoutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 4000\n",
    "for i in range(epochs):\n",
    "\n",
    "    output = model.forward(train_input)\n",
    "\n",
    "    gradwrrtxL = loss.backward(output, train_target)\n",
    "    model.backward(gradwrrtxL)\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        test_accuracyV = test_accuracy(model, test_input, test_target)\n",
    "        print(f\"E {i} Loss : {loss.forward(output, train_target):.2f} / train accuracy: {test_accuracy(model, train_input, train_target):.2f} / test accuracy: {test_accuracyV:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = model.forward(test_input)\n",
    "test[test > 0] = 1\n",
    "test[test <= 0] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    print(test[i], test_target[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
