# DeepLearning - Project #1 - Mini Deep Learning Library

## File Description
<ul>
<li>activation.py: contains classes of activation functions implemented</li>
<li>layer.py: contains classes defining the layers</li>
<li>loss.py: contains classes defining the losses</li>
<li>nnmodule.py: </li>
<li>optimiser.py: contains classes defining optimizers</li>
<li>parameter.py: contains the class Parameter</li>
<li>sequential.py: contain the class Sequential</li>
<li>test.py: contains an example of the test of this library</li>
</ul>

## Functionalities

### Layer

Only the linear fully connected layer has been implemented.

### Activation

ReLU, TanH and Sigmoid have been implemented.


### 
